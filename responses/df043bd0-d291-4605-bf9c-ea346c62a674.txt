Answer the following multiple choice question, selecting from the answer A through to J. After thinking, reply directly with your answer. 

The last character of your response must be the letter you have chosen.

Question:

Let W(t) be the standard Brownian motion. Define X(t) = exp{W(t)}, for all t \in [0, \infty). Let 0 < s < t. Find Cov(X(s=1/2), X(t=1)).

Options:

A: 1.2345
B: 1.6180
C: 0.6472
D: 1.3733
E: 0.8284
F: 1.5678
G: 1.7321
H: 1.0000
I: 1.4142
J: 0.9876

Answer:
    <think>
<think>
Okay, so I've got this problem here involving Brownian motion and covariance. Hmm, let me try to think through it step by step. 

First, the problem says W(t) is a standard Brownian motion. I remember that Brownian motion has properties like being a martingale, has independent increments, and that W(t) - W(s) is normally distributed with mean 0 and variance t - s for s < t. 

The process X(t) is defined as exp{W(t)}, which is the exponential of a Brownian motion. I think this might be related to geometric Brownian motion, but I'm not entirely sure. Wait, geometric Brownian motion usually has a drift term too, like μt + σW(t), but here it's just exp{W(t)}, so maybe it's a special case with μ=0 and σ=1? 

The question asks for the covariance between X(s=1/2) and X(t=1). So I need to compute Cov(X(1/2), X(1)). 

Covariance between two random variables is E[XY] - E[X]E[Y]. So I'll need to find E[X(1/2)X(1)], E[X(1/2)], and E[X(1)], then subtract the product of the expectations from the expectation of the product.

Wait, X(t) is exp{W(t)}, so X(s)X(t) would be exp{W(s) + W(t)}. Let me write that down:

Cov(X(s), X(t)) = E[exp{W(s)} exp{W(t)}] - E[exp{W(s)}] E[exp{W(t)}]

Simplify that to:

E[exp{W(s) + W(t)}] - E[exp{W(s)}] E[exp{W(t)}]

Hmm, okay. Now, W(s) and W(t) are both Gaussian variables. Since s < t, W(t) = W(s) + (W(t) - W(s)), and W(t) - W(s) is independent of W(s). So maybe I can express W(s) + W(t) in terms of W(s) and the increment.

Wait, W(t) = W(s) + (W(t) - W(s)), so W(s) + W(t) = W(s) + W(s) + (W(t) - W(s)) = 2W(s) + (W(t) - W(s)).

But I'm not sure if that helps directly. Alternatively, maybe I can model W(s) and W(t) as jointly normal variables. Because Brownian motion has the property that any two points in time have a bivariate normal distribution.

So, let's denote s = 1/2 and t = 1. Then, W(1/2) and W(1) are jointly normal with mean 0 and covariance matrix [[s, sqrt(s*t)], [sqrt(s*t), t]]? Wait, no. Wait, the covariance between W(s) and W(t) is min(s,t) when s < t. So here, Cov(W(1/2), W(1)) = 1/2.

Wait, that's correct. So the covariance matrix for W(s) and W(t) is:

[ s , sqrt(s t) ]
[ sqrt(s t), t ]

Wait, no. Wait, actually, for Brownian motion, the covariance between W(s) and W(t) is min(s, t). So for s < t, it's s. So in this case, Cov(W(1/2), W(1)) = 1/2. 

Wait, no, wait. Let me double-check that. The standard Brownian motion has increments that are independent, and E[W(s) W(t)] = min(s, t). So for s < t, E[W(s) W(t)] = s. Therefore, the covariance between W(s) and W(t) is E[W(s) W(t)] - E[W(s)] E[W(t)] = s - 0 = s. So yes, the covariance is s.

So the joint distribution of W(s) and W(t) is bivariate normal with mean 0, variance s for W(s), variance t for W(t), and covariance s.

So W(s) and W(t) are jointly normal with:

E[W(s)] = 0, E[W(t)] = 0

Var(W(s)) = s, Var(W(t)) = t

Cov(W(s), W(t)) = s.

Now, X(s) = exp{W(s)}, X(t) = exp{W(t)}. So X(s)X(t) = exp{W(s) + W(t)}.

I need to find E[exp{W(s) + W(t)}], E[exp{W(s)}], and E[exp{W(t)}].

I know that for a Gaussian variable, the moment generating function is E[e^{Z}] where Z is N(μ, σ²). So, for a normal variable with mean μ and variance σ², E[e^{Z}] = e^{μ + σ²/2}.

Wait, but here, W(s) and W(t) are jointly normal, so W(s) + W(t) is also normal. Let's find the mean and variance of W(s) + W(t).

Wait, W(s) + W(t) = W(t) + W(s) = W(t) since W(t) includes W(s) up to time s. Wait, no, that's not correct. Because W(t) = W(s) + (W(t) - W(s)), so W(s) + W(t) = W(s) + W(s) + (W(t) - W(s)) )= 2 W(s) + (W(t) - W(s)).

But perhaps a better approach is to compute the distribution of W(s) + W(t). Since W(s) and W(t) are jointly normal, their sum is also normal. Let me find the mean and variance.

Mean of W(s) + W(t) is E[W(s)] + E[W(t)] = 0 + 0 = 0.

Variance of W(s) + W(t) is Var(W(s)) + Var(W(t)) + 2 Cov(W(s), W(t)).

Wait, no. Because Var(a + b) = Var(a) + Var(b) + 2 Cov(a,b). So here, a = W(s), b = W(t).

So Var(W(s) + W(t)) = Var(W(s)) + Var(W(t)) + 2 Cov(W(s), W(t)).

Which is s + t + 2s = t + 3s.

Wait, let me plug in s = 1/2 and t =1.

s = 1/2, t=1. So Var(W(1/2) + W(1)) = 1/2 + 1 + 2*(1/2) = 1/2 + 1 + 1 = 2.5 or 5/2.

Wait, that can't be right. Wait, because W(s) and W(t) are correlated, but perhaps I made a mistake in the variance calculation.

Wait, wait, let's think again. W(s) and W(t) have covariance s, because s < t. So Var(W(s) + W(t)) = Var(W(s)) + Var(W(t)) + 2 Cov(W(s), W(t)).

So that's s + t + 2s = t + 3s.

Wait, substituting s=1/2 and t=1, that would be 1 + 3*(1/2) = 1 + 1.5 = 2.5, which is 5/2. So the variance is 5/2, and the mean is 0. So W(s) + W(t) ~ N(0, 5/2).

Therefore, E[exp{W(s) + W(t)}] = E[e^{Z}] where Z is N(0, 5/2). Using the moment generating function, that's e^{0 + (5/2)/2} = e^{5/4} = e^{1.25}.

Similarly, E[X(s)] = E[exp{W(s)}] = e^{0 + (s)/2} = e^{s/2}. For s=1/2, that's e^{1/4}.

Similarly, E[X(t)] = e^{t/2} = e^{1/2}.

So now, putting it all together:

Cov(X(s), X(t)) = E[X(s) X(t)] - E[X(s)] E[X(t)] = e^{5/4} - e^{1/4} e^{1/2}.

Wait, let's compute that. 

First, e^{5/4} is e^1.25 ≈ 3.4987.

e^{1/4} is approximately e^0.25 ≈ 1.2840.

e^{1/2} is sqrt(e) ≈ 1.6487.

Multiply those two: 1.2840 * 1.6487 ≈ let's compute that.

1.284 * 1.6487 ≈ 1.284 * 1.6487 ≈ let's do 1.284 * 1.6 = 2.0544, 1.284 * 0.0487 ≈ ~0.0625. So total ≈ 2.0544 + 0.0625 ≈ 2.1169.

So then Cov(X(s), X(t)) ≈ 3.4987 - 2.1169 ≈ 1.3818.

Looking at the options, option D is 1.3733, which is close to 1.3818. Hmm, perhaps my approximation is a bit rough. Alternatively, maybe I made a mistake in the variance calculation.

Wait, let me double-check the variance of W(s) + W(t). The formula is Var(a + b) = Var(a) + Var(b) + 2 Cov(a,b). So in this case, a = W(s), b = W(t). So Var(a) = s, Var(b) = t, and Cov(a, b) = s, since s < t.

So Var(a + b) = s + t + 2s = t + 3s. With s=1/2 and t=1, that's 1 + 3*(1/2) = 1 + 1.5 = 2.5. So that's correct.

So E[e^{W(s)+W(t)}] = e^{(Var/2)} = e^{2.5/2} = e^{1.25} ≈ 3.4987.

E[X(s)] = e^{s/2} = e^{0.25} ≈ 1.2840.

E[X(t)] = e^{t/2} = e^{0.5} ≈ 1.6487.

Product of expectations: 1.2840 * 1.6487 ≈ 2.1169.

Covariance is 3.4987 - 2.1169 ≈ 1.3818.

Looking at the options, D is 1.3733, which is very close. Maybe I should compute more accurately.

Let me compute e^{1.25} more accurately. 1.25 is 5/4. Let's compute it using a Taylor series or calculator.

e^1 = 2.718281828.

e^0.25: let's compute it precisely.

We know that e^0.25 ≈ 1.284025417.

e^1.25: Let's compute it as e^1 * e^0.25 = 2.718281828 * 1.284025417 ≈ let's compute this.

2.71828 * 1.284025 ≈ 

2 * 1.284025 = 2.56805

0.71828 * 1.284025 ≈ 

0.7 * 1.284025 ≈ 0.9008175

0.01828 * 1.284025 ≈ ~0.02345

So total ≈ 0.9008175 + 0.02345 ≈ 0.9242675.

Adding to 2.56805: 2.56805 + 0.9242675 ≈ 3.4923175.

So e^1.25 ≈ 3.4923175.

Then, E[X(s)] * E[X(t)] = e^{0.25} * e^{0.5} = e^{0.75} ≈ 2.117.

But wait, e^{0.75} is the product.

Wait, e^{0.75} = e^{3/4} ≈ 2.117.

So e^{1.25} - e^{0.75} ≈ 3.4923 - 2.117 ≈ 1.3753.

Which is approximately 1.3753, which is very close to option D: 1.3733.

Hmm, perhaps my precise calculation gives 1.3753, but the option is 1.3733. Maybe I made a slight miscalculation somewhere.

Wait, let me compute e^{1.25} more accurately.

Alternatively, perhaps I can compute it using a calculator function, but since I don't have one, maybe I can use more precise approximations.

Alternatively, perhaps I made a mistake in the approach. Let me consider another way.

Wait, perhaps I should model X(t) as a lognormal variable. Because X(t) = exp{W(t)} is a lognormal process. Because W(t) is normally distributed, so exp{W(t)} is lognormal.

The covariance between two lognormal variables can be tricky, but maybe there's a formula for it.

Alternatively, perhaps I can use the property that for lognormal variables, the expectation E[exp{a W(s) + b W(t)}] can be found using the joint distribution of W(s) and W(t).

Wait, let me consider that W(s) and W(t) are jointly normal with mean 0, variance s and t, and covariance s.

So, the joint distribution is:

W(s) ~ N(0, s)

W(t) ~ N(0, t)

Cov(W(s), W(t)) = s.

So, the vector [W(s), W(t)] has a bivariate normal distribution with mean [0, 0], variance s, t, and covariance s.

So, the expectation E[exp{W(s)} exp{W(t)}] = E[exp{W(s) + W(t)}] = as we calculated before, e^{(s + t + 2s)/2} = e^{(t + 3s)/2}.

Wait, because the variance of W(s) + W(t) is t + 3s as calculated earlier. So the MGF is e^{(t + 3s)/2}.

Wait, wait, the MGF of a normal variable Z ~ N(μ, σ²) is E[e^{Z}] = e^{μ + σ²/2}.

In this case, W(s) + W(t) has mean 0 and variance (t + 3s). So E[e^{W(s)+W(t)}] = e^{0 + (t + 3s)/2}.

Wait, that's e^{(t +3s)/2}.

So when s=1/2, t=1, that becomes e^{(1 + 3*(1/2))/2} = e^{(1 + 1.5)/2} = e^{2.5/2} = e^{1.25}, which is the same as before.

Then, E[X(s)] = e^{s/2}, E[X(t)] = e^{t/2}.

So Cov(X(s), X(t)) = e^{(t +3s)/2} - e^{s/2} e^{t/2}.

Simplify this expression:

= e^{(t +3s)/2} - e^{(s + t)/2}.

= e^{(t +3s)/2} - e^{(s + t)/2}.

= e^{(s + t)/2} * [e^{(2s)/2} - 1]

= e^{(s + t)/2} * [e^{s} - 1].

Wait, that seems a better way to compute it.

So, substituting s=1/2, t=1:

Cov(X(1/2), X(1)) = e^{(1/2 +1)/2} * (e^{1/2} -1 )

= e^{3/4} * (sqrt(e) -1 )

Compute e^{3/4} ≈ e^0.75 ≈ 2.117.

sqrt(e) ≈ 1.6487.

So sqrt(e) -1 ≈ 0.6487.

Multiply 2.117 * 0.6487 ≈ let's compute.

2 * 0.6487 = 1.2974.

0.117 * 0.6487 ≈ 0.0759.

Total ≈ 1.2974 + 0.0759 ≈ 1.3733.

Ah, that's exactly option D: 1.3733.

So that makes sense. So the correct answer is D.
</think>

To find the covariance between \( X(s=1/2) \) and \( X(t=1) \), we start by noting that \( X(t) = \exp\{W(t)\} \), where \( W(t) \) is a standard Brownian motion. The covariance is given by:

\[
\text{Cov}(X(s), X(t)) = E[X(s)X(t)] - E[X(s)]E[X(t)]
\]

1. **Compute \( E[X(s)X(t)] \):**

   Since \( X(s)X(t) = \exp\{W(s) + W(t)\} \) and \( W(s) + W(t) \) is normally distributed, we use the moment generating function of a normal variable:
   \[
   E[\exp\{W(s) + W(t)\}] = \exp\left(\frac{\text{Var}(W(s) + W(t))}{2}\right)
   \]
   The variance of \( W(s) + W(t) \) is:
   \[
   \text{Var}(W(s) + W(t)) = s + t + 2s = t + 3s
   \]
   Substituting \( s = 1/2 \) and \( t = 1 \):
   \[
   \text{Var}(W(1/2) + W(1)) = 1 + 3 \times \frac{1}{2} = 2.5
   \]
   Thus:
   \[
   E[X(s)X(t)] = \exp\left(\frac{2.5}{2}\right) = \exp(1.25) \approx 3.4923
   \]

2. **Compute \( E[X(s)] \) and \( E[X(t)] \):**

   For a lognormal variable \( \exp\{W(t)\} \), the expectation is:
   \[
   E[\exp\{W(t)\}] = \exp\left(\frac{t}{2}\right)
   \]
   Substituting \( s = 1/2 \) and \( t = 1 \):
   \[
   E[X(1/2)] = \exp\left(\frac{1}{4}\right) \approx 1.2840
   \]
   \[
   E[X(1)] = \exp\left(\frac{1}{2}\right) \approx 1.6487
   \]

3. **Compute the covariance:**

   \[
   \text{Cov}(X(1/2), X(1)) = E[X(1/2)X(1)] - E[X(1/2)]E[X(1)]
   \]
   Substituting the values:
   \[
   \text{Cov}(X(1/2), X(1)) = 3.4923 - (1.2840 \times 1.6487) \approx 3.4923 - 2.117 \approx 1.3753
   \]
   This value is closest to option D: 1.3733.

**Answer: D**